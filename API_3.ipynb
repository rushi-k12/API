{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvy3cU5iZrsglaGDa9uIyU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rushi-k12/API/blob/Further_Exploration_of_Optimizations/API_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rq37LwO72nPp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from requests import Request, Session\n",
        "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
        "import json\n",
        "\n",
        "url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'\n",
        "#Original Sandbox Environment: 'https://sandbox-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'\n",
        "parameters = {\n",
        "  'start':'1',\n",
        "  'limit':'15',\n",
        "  'convert':'USD'\n",
        "}\n",
        "headers = {\n",
        "  'Accepts': 'application/json',\n",
        "  'X-CMC_PRO_API_KEY': '0ad53085-1cb2-4eb8-ad9e-3ffbd7e56509',\n",
        "}\n",
        "\n",
        "session = Session()\n",
        "session.headers.update(headers)\n",
        "\n",
        "try:\n",
        "  response = session.get(url, params=parameters)\n",
        "  data = json.loads(response.text)\n",
        "  #print(data)\n",
        "except (ConnectionError, Timeout, TooManyRedirects) as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "id": "8rEjf2b6kJRo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.json_normalize(data['data'])\n"
      ],
      "metadata": {
        "id": "dmTGN3mjkOO9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWh5ZvrS4E2E",
        "outputId": "30085d9f-74d4-428d-dd2c-72e7ca3a1e1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'name', 'symbol', 'slug', 'num_market_pairs', 'date_added',\n",
              "       'tags', 'max_supply', 'circulating_supply', 'total_supply',\n",
              "       'infinite_supply', 'platform', 'cmc_rank',\n",
              "       'self_reported_circulating_supply', 'self_reported_market_cap',\n",
              "       'tvl_ratio', 'last_updated', 'quote.USD.price', 'quote.USD.volume_24h',\n",
              "       'quote.USD.volume_change_24h', 'quote.USD.percent_change_1h',\n",
              "       'quote.USD.percent_change_24h', 'quote.USD.percent_change_7d',\n",
              "       'quote.USD.percent_change_30d', 'quote.USD.percent_change_60d',\n",
              "       'quote.USD.percent_change_90d', 'quote.USD.market_cap',\n",
              "       'quote.USD.market_cap_dominance', 'quote.USD.fully_diluted_market_cap',\n",
              "       'quote.USD.tvl', 'quote.USD.last_updated', 'platform.id',\n",
              "       'platform.name', 'platform.symbol', 'platform.slug',\n",
              "       'platform.token_address'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4jkd5NC129cQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Feature selection/engineering\n",
        "# Select relevant features\n",
        "# Drop the target variable from the features\n",
        "features = df.drop(columns=['quote.USD.price'])\n",
        "# Other feature engineering steps...\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, df['quote.USD.price'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KCJGZLPDkcp0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vKivRhr129ew"
      },
      "outputs": [],
      "source": [
        "# Define the columns to keep\n",
        "selected_columns = [\n",
        "    'id', 'num_market_pairs', 'circulating_supply',\n",
        "    'total_supply', 'infinite_supply', 'cmc_rank',\n",
        "    'quote.USD.volume_24h', 'quote.USD.volume_change_24h',\n",
        "    'quote.USD.percent_change_1h', 'quote.USD.percent_change_24h',\n",
        "    'quote.USD.percent_change_7d', 'quote.USD.percent_change_30d',\n",
        "    'quote.USD.percent_change_60d', 'quote.USD.percent_change_90d',\n",
        "    'quote.USD.market_cap', 'quote.USD.market_cap_dominance',\n",
        "    'quote.USD.fully_diluted_market_cap'\n",
        "]\n",
        "\n",
        "# Select only the desired columns\n",
        "X_test_numeric = X_test.loc[:, selected_columns]\n",
        "X_train_numeric = X_train.loc[:, selected_columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1GdAKk255vcG"
      },
      "outputs": [],
      "source": [
        "xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load your data and preprocess it\n",
        "# For example:\n",
        "# df = pd.read_csv('your_data.csv')\n",
        "# X = df.drop(columns=['target_column'])\n",
        "# y = df['target_column']\n",
        "\n",
        "# Perform train-test split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize XGBoost regressor\n",
        "model_file_path = 'xgb_regressor_model.pkl'\n",
        "joblib.dump(xgb_regressor, model_file_path)\n"
      ],
      "metadata": {
        "id": "CX00oI0pkiEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a95efe3-3961-4cf7-cedf-2f99393f5d34"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xgb_regressor_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "from requests import Session\n",
        "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
        "import json\n",
        "\n",
        "# Function to fetch new data from the API\n",
        "def fetch_new_data_from_api():\n",
        "    url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'\n",
        "    parameters = {\n",
        "      'start':'1',\n",
        "      'limit':'5',\n",
        "      'convert':'USD'\n",
        "    }\n",
        "    headers = {\n",
        "      'Accepts': 'application/json',\n",
        "      'X-CMC_PRO_API_KEY': '0ad53085-1cb2-4eb8-ad9e-3ffbd7e56509',\n",
        "    }\n",
        "\n",
        "    session = Session()\n",
        "    session.headers.update(headers)\n",
        "\n",
        "    try:\n",
        "        response = session.get(url, params=parameters)\n",
        "        data = json.loads(response.text)\n",
        "        return data['data']\n",
        "    except (ConnectionError, Timeout, TooManyRedirects) as e:\n",
        "        print(e)\n",
        "        return None\n",
        "\n",
        "# Function to preprocess new data\n",
        "def preprocess_new_data(new_data):\n",
        "    df = pd.json_normalize(new_data)\n",
        "    df['timestamp'] = pd.to_datetime('now', utc=True)  # Fixing the FutureWarning\n",
        "\n",
        "    # Select relevant features\n",
        "    selected_columns = [\n",
        "        'id', 'num_market_pairs', 'circulating_supply',\n",
        "        'total_supply', 'infinite_supply', 'cmc_rank',\n",
        "        'quote.USD.volume_24h', 'quote.USD.volume_change_24h',\n",
        "        'quote.USD.percent_change_1h', 'quote.USD.percent_change_24h',\n",
        "        'quote.USD.percent_change_7d', 'quote.USD.percent_change_30d',\n",
        "        'quote.USD.percent_change_60d', 'quote.USD.percent_change_90d',\n",
        "        'quote.USD.market_cap', 'quote.USD.market_cap_dominance',\n",
        "        'quote.USD.fully_diluted_market_cap'\n",
        "    ]\n",
        "    X_test_numeric = df.loc[:, selected_columns]\n",
        "\n",
        "    return X_test_numeric\n",
        "\n",
        "# Function to make predictions using the loaded model\n",
        "def make_predictions(model, new_data):\n",
        "    preprocessed_data = preprocess_new_data(new_data)\n",
        "    predictions = model.predict(preprocessed_data)\n",
        "    return predictions\n",
        "\n",
        "# Load the trained model from the file\n",
        "model_file_path = 'xgb_regressor_model.pkl'\n",
        "loaded_model = joblib.load(model_file_path)\n",
        "\n",
        "# Fetch new data from the API\n",
        "new_data = fetch_new_data_from_api()\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "if new_data is not None:\n",
        "    predictions = make_predictions(loaded_model, new_data)\n",
        "    print(\"Predictions:\", predictions)\n",
        "else:\n",
        "    print(\"Failed to fetch new data from the API.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "vNAaq4JiIGYP",
        "outputId": "3bb5d15c-cdf4-4189-a6d4-9cfa756a52d0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "need to call fit or load_model beforehand",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-4d4a1ba372fb>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Make predictions using the loaded model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predictions:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-4d4a1ba372fb>\u001b[0m in \u001b[0;36mmake_predictions\u001b[0;34m(model, new_data)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mpreprocessed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_new_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1166\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_use_inplace_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m                     predts = self.get_booster().inplace_predict(\n\u001b[0m\u001b[1;32m   1169\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                         \u001b[0miteration_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"need to call fit or load_model beforehand\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRXT7RsG24I8",
        "outputId": "ad31cf5b-9301-467b-c928-23a58f50d5be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xgb_regressor_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Define the file path where you want to save the model\n",
        "model_file_path = 'xgb_regressor_model.pkl'\n",
        "\n",
        "# Save the trained model to the specified file path\n",
        "joblib.dump(xgb_regressor, model_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upc6b_znbbWl",
        "outputId": "90b17304-386c-411a-aea1-10ae47470136"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'name', 'symbol', 'slug', 'num_market_pairs', 'date_added',\n",
              "       'tags', 'max_supply', 'circulating_supply', 'total_supply',\n",
              "       'infinite_supply', 'platform', 'cmc_rank',\n",
              "       'self_reported_circulating_supply', 'self_reported_market_cap',\n",
              "       'tvl_ratio', 'last_updated', 'quote.USD.volume_24h',\n",
              "       'quote.USD.volume_change_24h', 'quote.USD.percent_change_1h',\n",
              "       'quote.USD.percent_change_24h', 'quote.USD.percent_change_7d',\n",
              "       'quote.USD.percent_change_30d', 'quote.USD.percent_change_60d',\n",
              "       'quote.USD.percent_change_90d', 'quote.USD.market_cap',\n",
              "       'quote.USD.market_cap_dominance', 'quote.USD.fully_diluted_market_cap',\n",
              "       'quote.USD.tvl', 'quote.USD.last_updated', 'platform.id',\n",
              "       'platform.name', 'platform.symbol', 'platform.slug',\n",
              "       'platform.token_address'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "from requests import Session\n",
        "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
        "import json\n",
        "\n",
        "# Function to fetch new data from the API\n",
        "def fetch_new_data_from_api():\n",
        "    url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'\n",
        "    parameters = {\n",
        "      'start':'1',\n",
        "      'limit':'5',\n",
        "      'convert':'USD'\n",
        "    }\n",
        "    headers = {\n",
        "      'Accepts': 'application/json',\n",
        "      'X-CMC_PRO_API_KEY': '0ad53085-1cb2-4eb8-ad9e-3ffbd7e56509',\n",
        "    }\n",
        "\n",
        "    session = Session()\n",
        "    session.headers.update(headers)\n",
        "\n",
        "    try:\n",
        "        response = session.get(url, params=parameters)\n",
        "        data = json.loads(response.text)\n",
        "        return data['data']\n",
        "    except (ConnectionError, Timeout, TooManyRedirects) as e:\n",
        "        print(e)\n",
        "        return None\n",
        "\n",
        "# Function to preprocess new data\n",
        "def preprocess_new_data(new_data):\n",
        "    df = pd.json_normalize(new_data)\n",
        "    df['timestamp'] = pd.to_datetime('now')\n",
        "\n",
        "    # Select relevant features\n",
        "    selected_columns = [\n",
        "        'id', 'num_market_pairs', 'circulating_supply',\n",
        "        'total_supply', 'infinite_supply', 'cmc_rank',\n",
        "        'quote.USD.volume_24h', 'quote.USD.volume_change_24h',\n",
        "        'quote.USD.percent_change_1h', 'quote.USD.percent_change_24h',\n",
        "        'quote.USD.percent_change_7d', 'quote.USD.percent_change_30d',\n",
        "        'quote.USD.percent_change_60d', 'quote.USD.percent_change_90d',\n",
        "        'quote.USD.market_cap', 'quote.USD.market_cap_dominance',\n",
        "        'quote.USD.fully_diluted_market_cap'\n",
        "    ]\n",
        "    X_test_numeric = df.loc[:, selected_columns]\n",
        "\n",
        "    return X_test_numeric\n",
        "\n",
        "# Function to make predictions using the loaded model\n",
        "def make_predictions(model, new_data):\n",
        "    preprocessed_data = preprocess_new_data(new_data)\n",
        "    predictions = model.predict(preprocessed_data)\n",
        "    return predictions\n",
        "\n",
        "# Load the trained model from the .pkl file\n",
        "model_file_path = 'xgb_regressor_model.pkl'\n",
        "loaded_model = joblib.load(model_file_path)\n",
        "\n",
        "# Fetch new data from the API\n",
        "new_data = fetch_new_data_from_api()\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "if new_data is not None:\n",
        "    predictions = make_predictions(loaded_model, new_data)\n",
        "    print(\"Predictions:\", predictions)\n",
        "else:\n",
        "    print(\"Failed to fetch new data from the API.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "Llm3CYuEbiiS",
        "outputId": "e3706868-24a7-4701-e0b6-f086088bddb1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-eb8b9b7d3b7f>:36: FutureWarning: The parsing of 'now' in pd.to_datetime without `utc=True` is deprecated. In a future version, this will match Timestamp('now') and Timestamp.now()\n",
            "  df['timestamp'] = pd.to_datetime('now')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "need to call fit or load_model beforehand",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-eb8b9b7d3b7f>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Make predictions using the loaded model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predictions:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-eb8b9b7d3b7f>\u001b[0m in \u001b[0;36mmake_predictions\u001b[0;34m(model, new_data)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mpreprocessed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_new_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1166\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_use_inplace_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m                     predts = self.get_booster().inplace_predict(\n\u001b[0m\u001b[1;32m   1169\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                         \u001b[0miteration_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"need to call fit or load_model beforehand\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Taj5V8FfdFKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "455fc359-1f74-4885-f6e1-feeab9ed5f73",
        "id": "s9aGiJn5hGog"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "need to call fit or load_model beforehand",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-745adeab8b32>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Make predictions using the loaded model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predictions:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-745adeab8b32>\u001b[0m in \u001b[0;36mmake_predictions\u001b[0;34m(model, new_data)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mpreprocessed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_new_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1166\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_use_inplace_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m                     predts = self.get_booster().inplace_predict(\n\u001b[0m\u001b[1;32m   1169\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                         \u001b[0miteration_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"need to call fit or load_model beforehand\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "from requests import Session\n",
        "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
        "import json\n",
        "\n",
        "# Function to fetch new data from the API\n",
        "def fetch_new_data_from_api():\n",
        "    url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'\n",
        "    parameters = {\n",
        "      'start':'1',\n",
        "      'limit':'15',\n",
        "      'convert':'USD'\n",
        "    }\n",
        "    headers = {\n",
        "      'Accepts': 'application/json',\n",
        "      'X-CMC_PRO_API_KEY': '0ad53085-1cb2-4eb8-ad9e-3ffbd7e56509',\n",
        "    }\n",
        "\n",
        "    session = Session()\n",
        "    session.headers.update(headers)\n",
        "\n",
        "    try:\n",
        "        response = session.get(url, params=parameters)\n",
        "        data = json.loads(response.text)\n",
        "        return data['data']\n",
        "    except (ConnectionError, Timeout, TooManyRedirects) as e:\n",
        "        print(e)\n",
        "        return None\n",
        "\n",
        "\n",
        "    # Select relevant features\n",
        "    selected_columns = [\n",
        "        'id', 'num_market_pairs', 'circulating_supply',\n",
        "        'total_supply', 'infinite_supply', 'cmc_rank',\n",
        "        'quote.USD.volume_24h', 'quote.USD.volume_change_24h',\n",
        "        'quote.USD.percent_change_1h', 'quote.USD.percent_change_24h',\n",
        "        'quote.USD.percent_change_7d', 'quote.USD.percent_change_30d',\n",
        "        'quote.USD.percent_change_60d', 'quote.USD.percent_change_90d',\n",
        "        'quote.USD.market_cap', 'quote.USD.market_cap_dominance',\n",
        "        'quote.USD.fully_diluted_market_cap'\n",
        "    ]\n",
        "    X_test_numeric = df.loc[:, selected_columns]\n",
        "\n",
        "    return X_test_numeric\n",
        "\n",
        "# Function to make predictions using the loaded model\n",
        "def make_predictions(model, new_data):\n",
        "    preprocessed_data = preprocess_new_data(new_data)\n",
        "    predictions = model.predict(preprocessed_data)\n",
        "    return predictions\n",
        "\n",
        "# Load the trained model from the .pkl file\n",
        "model_file_path = 'xgb_regressor_model.pkl'\n",
        "loaded_model = joblib.load(model_file_path)\n",
        "\n",
        "# Fetch new data from the API\n",
        "new_data = fetch_new_data_from_api()\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "if new_data is not None:\n",
        "    predictions = make_predictions(loaded_model, new_data)\n",
        "    print(\"Predictions:\", predictions)\n",
        "else:\n",
        "    print(\"Failed to fetch new data from the API.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kf7TUCBseBnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "103dbc1c-cedc-4539-af2a-1a4d87e1e4c3",
        "id": "zzmA3O-veRJD"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-eb8b9b7d3b7f>:36: FutureWarning: The parsing of 'now' in pd.to_datetime without `utc=True` is deprecated. In a future version, this will match Timestamp('now') and Timestamp.now()\n",
            "  df['timestamp'] = pd.to_datetime('now')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "need to call fit or load_model beforehand",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-745adeab8b32>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Make predictions using the loaded model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predictions:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-745adeab8b32>\u001b[0m in \u001b[0;36mmake_predictions\u001b[0;34m(model, new_data)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mpreprocessed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_new_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1166\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_use_inplace_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m                     predts = self.get_booster().inplace_predict(\n\u001b[0m\u001b[1;32m   1169\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                         \u001b[0miteration_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"need to call fit or load_model beforehand\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "from requests import Session\n",
        "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
        "import json\n",
        "\n",
        "# Function to fetch new data from the API\n",
        "def fetch_new_data_from_api():\n",
        "    url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'\n",
        "    parameters = {\n",
        "      'start':'1',\n",
        "      'limit':'15',\n",
        "      'convert':'USD'\n",
        "    }\n",
        "    headers = {\n",
        "      'Accepts': 'application/json',\n",
        "      'X-CMC_PRO_API_KEY': '0ad53085-1cb2-4eb8-ad9e-3ffbd7e56509',\n",
        "    }\n",
        "\n",
        "    session = Session()\n",
        "    session.headers.update(headers)\n",
        "\n",
        "    try:\n",
        "        response = session.get(url, params=parameters)\n",
        "        data = json.loads(response.text)\n",
        "        return data['data']\n",
        "    except (ConnectionError, Timeout, TooManyRedirects) as e:\n",
        "        print(e)\n",
        "        return None\n",
        "\n",
        "\n",
        "    # Select relevant features\n",
        "    selected_columns = [\n",
        "        'id', 'num_market_pairs', 'circulating_supply',\n",
        "        'total_supply', 'infinite_supply', 'cmc_rank',\n",
        "        'quote.USD.volume_24h', 'quote.USD.volume_change_24h',\n",
        "        'quote.USD.percent_change_1h', 'quote.USD.percent_change_24h',\n",
        "        'quote.USD.percent_change_7d', 'quote.USD.percent_change_30d',\n",
        "        'quote.USD.percent_change_60d', 'quote.USD.percent_change_90d',\n",
        "        'quote.USD.market_cap', 'quote.USD.market_cap_dominance',\n",
        "        'quote.USD.fully_diluted_market_cap'\n",
        "    ]\n",
        "    X_test_numeric = df.loc[:, selected_columns]\n",
        "\n",
        "    return X_test_numeric\n",
        "\n",
        "# Function to make predictions using the loaded model\n",
        "def make_predictions(model, new_data):\n",
        "    preprocessed_data = preprocess_new_data(new_data)\n",
        "    predictions = model.predict(preprocessed_data)\n",
        "    return predictions\n",
        "\n",
        "# Load the trained model from the .pkl file\n",
        "model_file_path = 'xgb_regressor_model.pkl'\n",
        "loaded_model = joblib.load(model_file_path)\n",
        "\n",
        "# Fetch new data from the API\n",
        "new_data = fetch_new_data_from_api()\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "if new_data is not None:\n",
        "    predictions = make_predictions(loaded_model, new_data)\n",
        "    print(\"Predictions:\", predictions)\n",
        "else:\n",
        "    print(\"Failed to fetch new data from the API.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from requests import Request, Session\n",
        "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the function to fetch new data from the API\n",
        "def fetch_new_data_from_api():\n",
        "    url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'\n",
        "    parameters = {\n",
        "      'start':'1',\n",
        "      'limit':'5',\n",
        "      'convert':'USD'\n",
        "    }\n",
        "    headers = {\n",
        "      'Accepts': 'application/json',\n",
        "      'X-CMC_PRO_API_KEY': '0ad53085-1cb2-4eb8-ad9e-3ffbd7e56509',\n",
        "    }\n",
        "\n",
        "    session = Session()\n",
        "    session.headers.update(headers)\n",
        "\n",
        "    try:\n",
        "        response = session.get(url, params=parameters)\n",
        "        data = json.loads(response.text)\n",
        "        return data['data']\n",
        "    except (ConnectionError, Timeout, TooManyRedirects) as e:\n",
        "        print(e)\n",
        "        return None\n",
        "\n",
        "# Define the function to preprocess new data\n",
        "def preprocess_new_data(new_data):\n",
        "    df = pd.json_normalize(new_data)\n",
        "    df['timestamp'] = pd.to_datetime('now')\n",
        "\n",
        "    # Select relevant features\n",
        "    selected_columns = [\n",
        "        'id', 'num_market_pairs', 'circulating_supply',\n",
        "        'total_supply', 'infinite_supply', 'cmc_rank',\n",
        "        'quote.USD.volume_24h', 'quote.USD.volume_change_24h',\n",
        "        'quote.USD.percent_change_1h', 'quote.USD.percent_change_24h',\n",
        "        'quote.USD.percent_change_7d', 'quote.USD.percent_change_30d',\n",
        "        'quote.USD.percent_change_60d', 'quote.USD.percent_change_90d',\n",
        "        'quote.USD.market_cap', 'quote.USD.market_cap_dominance',\n",
        "        'quote.USD.fully_diluted_market_cap'\n",
        "    ]\n",
        "    X_test_numeric = df.loc[:, selected_columns]\n",
        "\n",
        "    return X_test_numeric\n",
        "\n",
        "# Define the function to make predictions using the loaded model\n",
        "def make_predictions(model, new_data):\n",
        "    preprocessed_data = preprocess_new_data(new_data)\n",
        "    predictions = model.predict(preprocessed_data)\n",
        "    return predictions\n",
        "\n",
        "# Load the trained model from the .pkl file\n",
        "model_file_path = 'xgb_regressor_model.pkl'\n",
        "loaded_model = joblib.load(model_file_path)\n",
        "\n",
        "# Fetch new data from the API\n",
        "new_data = fetch_new_data_from_api()\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "if new_data is not None:\n",
        "    predictions = make_predictions(loaded_model, new_data)\n",
        "    print(\"Predictions:\", predictions)\n",
        "else:\n",
        "    print(\"Failed to fetch new data from the API.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3SIrOkToeSqi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "f1fad16d-fa48-402b-cd1e-346139ef84dd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-47c5485c472d>:37: FutureWarning: The parsing of 'now' in pd.to_datetime without `utc=True` is deprecated. In a future version, this will match Timestamp('now') and Timestamp.now()\n",
            "  df['timestamp'] = pd.to_datetime('now')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "need to call fit or load_model beforehand",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-47c5485c472d>\u001b[0m in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# Make predictions using the loaded model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predictions:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-47c5485c472d>\u001b[0m in \u001b[0;36mmake_predictions\u001b[0;34m(model, new_data)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mpreprocessed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_new_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1166\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_use_inplace_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m                     predts = self.get_booster().inplace_predict(\n\u001b[0m\u001b[1;32m   1169\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                         \u001b[0miteration_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"need to call fit or load_model beforehand\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from requests import Request, Session\n",
        "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Function to fetch new data from the API\n",
        "def fetch_new_data_from_api():\n",
        "    url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'\n",
        "    parameters = {\n",
        "      'start':'1',\n",
        "      'limit':'5',\n",
        "      'convert':'USD'\n",
        "    }\n",
        "    headers = {\n",
        "      'Accepts': 'application/json',\n",
        "      'X-CMC_PRO_API_KEY': '0ad53085-1cb2-4eb8-ad9e-3ffbd7e56509',\n",
        "    }\n",
        "\n",
        "    session = Session()\n",
        "    session.headers.update(headers)\n",
        "\n",
        "    try:\n",
        "        response = session.get(url, params=parameters)\n",
        "        data = json.loads(response.text)\n",
        "        return data['data']\n",
        "    except (ConnectionError, Timeout, TooManyRedirects) as e:\n",
        "        print(e)\n",
        "        return None\n",
        "\n",
        "# Function to preprocess new data\n",
        "# Function to preprocess new data\n",
        "def preprocess_new_data(data):\n",
        "    df = pd.json_normalize(data)\n",
        "    df['timestamp'] = pd.to_datetime('now', utc=True)  # Fixing the FutureWarning\n",
        "\n",
        "    # Select relevant features\n",
        "    selected_columns = [\n",
        "        'id', 'num_market_pairs', 'circulating_supply',\n",
        "        'total_supply', 'infinite_supply', 'cmc_rank',\n",
        "        'quote.USD.volume_24h', 'quote.USD.volume_change_24h',\n",
        "        'quote.USD.percent_change_1h', 'quote.USD.percent_change_24h',\n",
        "        'quote.USD.percent_change_7d', 'quote.USD.percent_change_30d',\n",
        "        'quote.USD.percent_change_60d', 'quote.USD.percent_change_90d',\n",
        "        'quote.USD.market_cap', 'quote.USD.market_cap_dominance',\n",
        "        'quote.USD.fully_diluted_market_cap'\n",
        "    ]\n",
        "    X_test_numeric = df.loc[:, selected_columns]\n",
        "\n",
        "    return X_test_numeric\n",
        "\n",
        "# Function to make predictions using the loaded model\n",
        "def make_predictions(model, data):\n",
        "    preprocessed_data = preprocess_new_data(new_data)\n",
        "    predictions = model.predict(preprocessed_data)\n",
        "    return predictions\n",
        "\n",
        "# Train-test split\n",
        "# Replace this with your actual data loading and preprocessing steps\n",
        "# X_train, X_test, y_train, y_test = train_test_split(features, df['quote.USD.price'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Assuming you have already trained your model\n",
        "# Replace this with your actual model training code\n",
        "xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "# xgb_regressor.fit(X_train, y_train)  # Train your model\n",
        "\n",
        "# Save the trained model to a file\n",
        "model_file_path = 'xgb_regressor_model.pkl'\n",
        "joblib.dump(xgb_regressor, model_file_path)\n",
        "\n",
        "# Load the trained model from the file\n",
        "loaded_model = joblib.load(model_file_path)\n",
        "\n",
        "# Fetch new data from the API\n",
        "data = fetch_new_data_from_api()\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "if data is not None:\n",
        "    predictions = make_predictions(loaded_model, data)\n",
        "    print(\"Predictions:\", predictions)\n",
        "else:\n",
        "    print(\"Failed to fetch new data from the API.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "GgWA_OPYHNH9",
        "outputId": "cafb73b4-7773-4d84-943e-b9984776f160"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "need to call fit or load_model beforehand",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-8423577a1459>\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# Make predictions using the loaded model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predictions:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-8423577a1459>\u001b[0m in \u001b[0;36mmake_predictions\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mpreprocessed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_new_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1166\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_use_inplace_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m                     predts = self.get_booster().inplace_predict(\n\u001b[0m\u001b[1;32m   1169\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                         \u001b[0miteration_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"need to call fit or load_model beforehand\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZN_qHWfwfGu2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}